{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# storage\n",
    "from Storage.TFStorage import *\n",
    "\n",
    "# Config\n",
    "import Utils.Eva_config_consts as config\n",
    "\n",
    "# Utilities\n",
    "import Utils.folder_utils as folder_utils\n",
    "import Utils.TIMIT_utils as TIMIT_utils\n",
    "import Utils.image_utils as image_utils\n",
    "\n",
    "# Sound utils\n",
    "from Utils.nist_reader import NistReader\n",
    "import Utils.sound_utils as sound_utils\n",
    "\n",
    "# Spectrograms and MFCC\n",
    "from Utils.MFCC import *\n",
    "# from Utils.SpectrogramFactory import SpectrogramFactory\n",
    "# from Utils.Spectrogram import Spectrogram\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CutPhonemeIntoChunksAndSave(storage, phoneme_spectrums, chunkLength, phoneme, speaker):\n",
    "    \"\"\"\n",
    "    Accepts a spectrogram of arbitrary size of one concrete phoneme. Cuts chunks of size chunkLength which\n",
    "    will be input for the neural network. This gives the opportunity to deal with different phoneme length.\n",
    "    To create as many and as variable chunk spectrograms for the specified phoneme the shift of size 1 is used.\n",
    "    Finally, a cut chunk is saved to the storage.\n",
    "\n",
    "    :param storage: a TFStorage storage\n",
    "    :param phoneme_spectrums: Cut phoneme spectrogram\n",
    "    :param chunkLength: spectrogram chunk length which defines how many spectrums are considered\n",
    "    around the middle one. The middle one defines the phoneme and speaker.\n",
    "    :param phoneme: Phoneme string value\n",
    "    :param speaker: Speaker string value\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    \n",
    "    totalNumberOfSpectrums = phoneme_spectrums.shape[1]\n",
    "    #The stepLength is 1 therefore the number of chunks is calculated as follows\n",
    "    numChunks = totalNumberOfSpectrums-chunkLength + 1\n",
    "\n",
    "    for i in range(numChunks):\n",
    "        chunk = phoneme_spectrums[:,i:i+chunkLength]\n",
    "        real = np.real(chunk)\n",
    "        imag = np.imag(chunk)\n",
    "        phone_item = np.stack((real,imag), axis=-1)\n",
    "        row = (phone_item, phoneme, speaker)\n",
    "        storage.insert_row(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paths = folder_utils.reverse_folder(config.PATH_TO_TIMIT_TRAIN, \".WAV\")\n",
    "nistReader = NistReader()\n",
    "# Generate the mel filters\n",
    "mel_filter, mel_inversion_filter = create_mel_filter(fft_size = config.WINDOW_SIZE,\n",
    "                                                        n_freq_components = config.NUM_MEL_FREQ_COMPONENTS,\n",
    "                                                        start_freq = config.START_FREQ,\n",
    "                                                        end_freq = config.END_FREQ,\n",
    "                                                        samplerate=config.FRAME_RATE)\n",
    "# spectrogramFactory = SpectrogramFactory(window_size=config.WINDOW_SIZE, window_step=config.WINDOW_STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data/TIMIT/timit/train/dr1'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One folder dr1 test\n",
    "dr1_path = os.path.join(config.PATH_TO_TIMIT_TRAIN, \"dr1\")\n",
    "paths = folder_utils.reverse_folder(dr1_path, \".WAV\")\n",
    "dr1_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to find file: /Volumes/BOOTCAMP/EVA/TimitStore.tfrecords",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-12f3f5ebd189>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mTFStorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATESET_FILE_PATH\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTFStorageOpenOptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWRITE\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mphonemes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTIMIT_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_phoneme_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mspeaker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfolder_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_speaker_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Sergey/VoiceConvertor/Storage/TFStorage.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, openOption)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \"\"\"\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Failed to find file: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to find file: /Volumes/BOOTCAMP/EVA/TimitStore.tfrecords"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "with TFStorage(config.DATESET_FILE_PATH(), TFStorageOpenOptions.WRITE) as storage:\n",
    "    for path in paths:\n",
    "        print path\n",
    "        phonemes = TIMIT_utils.parse_phoneme_file(path)\n",
    "        speaker = folder_utils.get_speaker_name(path)\n",
    "\n",
    "        # temp_speaker_folder is used for storing converted to wav audio files.\n",
    "        temp_speaker_folder = os.path.join(config.TEMP_DATA_FOLDER_PATH, speaker)\n",
    "        if not os.path.exists(temp_speaker_folder):\n",
    "            os.makedirs(temp_speaker_folder)\n",
    "\n",
    "        # convert a nist file to a wav file\n",
    "        wav_file = nistReader.Nist2Wav(path, temp_speaker_folder)\n",
    "        for i in range(len(phonemes)):\n",
    "            phoneme = phonemes[i]\n",
    "            #Cutting one phoneme\n",
    "            if i == 0 or i == len(phonemes):\n",
    "                start = int(phoneme[0])\n",
    "                end = int(phoneme[1])\n",
    "            else:\n",
    "                start = int(phoneme[0]) - config.PHONEME_OFFSET\n",
    "                end = int(phoneme[1]) + config.PHONEME_OFFSET\n",
    "\n",
    "            # TODO: create a phoneme object\n",
    "            phone_file = sound_utils.cutPhonemeChunk(wav_file, config.TEMP_PHONEME_FOLDER_PATH, start, end, phoneme[2])\n",
    "            phone_wave_form, frame_rate = sound_utils.get_wav_info(phone_file)\n",
    "            \n",
    "            # create spectrogram of a phone chunk\n",
    "            phoneme_spectrogram = pretty_spectrogram(phone_wave_form, fft_size = config.WINDOW_SIZE, \n",
    "                                   step_size = config.WINDOW_STEP, log = True, thresh = config.SPEC_THRESH)\n",
    "            # create mels out of spectrogram\n",
    "            mel_spec = make_mel(phoneme_spectrogram, mel_filter, shorten_factor = 1)\n",
    "            \n",
    "            phone_subset = CutPhonemeIntoChunksAndSave(storage, mel_spec,\n",
    "                                                   config.SPECTROGRAM_CHUNK_LENGTH, phoneme[2], speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}