{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# storage\n",
    "from Storage.TFStorage import *\n",
    "\n",
    "# Config\n",
    "import Utils.Eva_config_consts as config\n",
    "\n",
    "# Utilities\n",
    "import Utils.folder_utils as folder_utils\n",
    "import Utils.TIMIT_utils as TIMIT_utils\n",
    "import Utils.image_utils as image_utils\n",
    "\n",
    "# Sound utils\n",
    "from Utils.nist_reader import NistReader\n",
    "import Utils.sound_utils as sound_utils\n",
    "\n",
    "# Spectrograms\n",
    "from Utils.SpectrogramFactory import SpectrogramFactory\n",
    "from Utils.Spectrogram import Spectrogram\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CutPhonemeIntoChunksAndSave(storage, phoneme_spectrums, chunkLength, phoneme, speaker):\n",
    "    \"\"\"\n",
    "    Accepts a spectrogram of arbitrary size of one concrete phoneme. Cuts chunks of size chunkLength which\n",
    "    will be input for the neural network. This gives the opportunity to deal with different phoneme length.\n",
    "    To create as many and as variable chunk spectrograms for the specified phoneme the shift of size 1 is used.\n",
    "    Finally, a cut chunk is saved to the storage.\n",
    "\n",
    "    :param storage: a TFStorage storage\n",
    "    :param phoneme_spectrums: Cut phoneme spectrogram\n",
    "    :param chunkLength: spectrogram chunk length which defines how many spectrums are considered\n",
    "    around the middle one. The middle one defines the phoneme and speaker.\n",
    "    :param phoneme: Phoneme string value\n",
    "    :param speaker: Speaker string value\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    \n",
    "    totalNumberOfSpectrums = phoneme_spectrums.shape[1]\n",
    "    #The stepLength is 1 therefore the number of chunks is calculated as follows\n",
    "    numChunks = totalNumberOfSpectrums-chunkLength + 1\n",
    "\n",
    "    for i in range(numChunks):\n",
    "        chunk = phoneme_spectrums[:,i:i+chunkLength]\n",
    "        real = np.real(chunk)\n",
    "        imag = np.imag(chunk)\n",
    "        phone_item = np.stack((real,imag), axis=-1)\n",
    "        row = (phone_item, phoneme, speaker)\n",
    "        storage.insert_row(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paths = folder_utils.reverse_folder(config.PATH_TO_TIMIT_TRAIN, \".WAV\")\n",
    "nistReader = NistReader()\n",
    "spectrogramFactory = SpectrogramFactory(window_size=config.WINDOW_SIZE, window_step=config.WINDOW_STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data/TIMIT/timit/train/dr1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One folder dr1 test\n",
    "dr1_path = os.path.join(config.PATH_TO_TIMIT_TRAIN, \"dr1\")\n",
    "paths = folder_utils.reverse_folder(dr1_path, \".WAV\")\n",
    "dr1_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/TIMIT/timit/train/dr1/fcjf0/SA1.WAV\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/TIMIT/timit/train/dr1/fcjf0/SA2.WAV\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/TIMIT/timit/train/dr1/fcjf0/SI1027.WAV\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/TIMIT/timit/train/dr1/fcjf0/SI1657.WAV\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/TIMIT/timit/train/dr1/fcjf0/SI648.WAV\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/TIMIT/timit/train/dr1/fcjf0/SX127.WAV\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/TIMIT/timit/train/dr1/fcjf0/SX217.WAV\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/TIMIT/timit/train/dr1/fcjf0/SX307.WAV\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-2a55391df0de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mphoneme_spectrogram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspectrogramFactory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_spectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphone_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             phone_subset = CutPhonemeIntoChunksAndSave(storage, phoneme_spectrogram.spectrogram_values,\n\u001b[0;32m---> 28\u001b[0;31m                                                    config.SPECTROGRAM_CHUNK_LENGTH, phoneme[2], speaker)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-22d4cb7ee634>\u001b[0m in \u001b[0;36mCutPhonemeIntoChunksAndSave\u001b[0;34m(storage, phoneme_spectrums, chunkLength, phoneme, speaker)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mphone_item\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mphone_item\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphoneme\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspeaker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Sergey/VoiceConvertor/Storage/TFStorage.pyc\u001b[0m in \u001b[0;36minsert_row\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     76\u001b[0m             'spectrum_raw': _bytes_feature(spectrum_raw)}))\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;31m# Reader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Sergey/anaconda/lib/python2.7/site-packages/tensorflow/python/lib/io/tf_record.pyc\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    124\u001b[0m       \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \"\"\"\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWriteRecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Sergey/anaconda/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.pyc\u001b[0m in \u001b[0;36mWriteRecord\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mWriteRecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyRecordWriter_WriteRecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mClose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "with TFStorage(config.DATESET_FILE_PATH, TFStorageOpenOptions.WRITE) as storage:\n",
    "    for path in paths:\n",
    "        print path\n",
    "        phonemes = TIMIT_utils.parse_phoneme_file(path)\n",
    "        speaker = folder_utils.get_speaker_name(path)\n",
    "\n",
    "        # temp_speaker_folder is used for storing converted to wav audio files.\n",
    "        temp_speaker_folder = os.path.join(config.TEMP_DATA_FOLDER_PATH, speaker)\n",
    "        if not os.path.exists(temp_speaker_folder):\n",
    "            os.makedirs(temp_speaker_folder)\n",
    "\n",
    "        # convert a nist file to a wav file\n",
    "        wav_file = nistReader.Nist2Wav(path, temp_speaker_folder)\n",
    "        for i in range(len(phonemes)):\n",
    "            phoneme = phonemes[i]\n",
    "            #Cutting one phoneme\n",
    "            if i == 0 or i == len(phonemes):\n",
    "                start = int(phoneme[0])\n",
    "                end = int(phoneme[1])\n",
    "            else:\n",
    "                start = int(phoneme[0]) - config.PHONEME_OFFSET\n",
    "                end = int(phoneme[1]) + config.PHONEME_OFFSET\n",
    "\n",
    "            # TODO: create a phoneme object\n",
    "            phone_file = sound_utils.cutPhonemeChunk(wav_file, config.TEMP_PHONEME_FOLDER_PATH, start, end, phoneme[2])\n",
    "            phoneme_spectrogram = spectrogramFactory.create_spectrogram(phone_file)\n",
    "            phone_subset = CutPhonemeIntoChunksAndSave(storage, phoneme_spectrogram.spectrogram_values,\n",
    "                                                   config.SPECTROGRAM_CHUNK_LENGTH, phoneme[2], speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}